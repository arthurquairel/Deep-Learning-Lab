# -*- coding: utf-8 -*-
"""Quairel_Arthur_DL_debut.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15ThxTiyj_7KTdsvqyk95iHDlTTc-XKbc

# Fashion-MNIST dataset & Feed-Forward Neural Networks with PyTorch

***

# Foreword
This notebook serves as **a template** for your experiments and explorations. You are encouraged not only to write the necessary code to complete the assigned tasks but also **to document your work clearly**. This includes **adding Markdown cells with your explanations, conclusions, and figures**. *The goal is for you to make this notebook into a nice report!*

Here are **a few key points** to keep in mind:

- Make sure you understand the code you write.

- Clearly explain your results and observations.

- Write clean, well-documented code.

- Avoid copy-pasting the same code multiple times — instead, define reusable functions!

# Main Objective: Image Classification

This lab introduces **feed-forward neural networks using PyTorch**, with a focus on **image classification**. You’ll work with the Fashion-MNIST dataset (see [Fashion-MNIST GitHub](https://github.com/zalandoresearch/fashion-mnist) for more details), which consists of:
- 60,000 training images
- 10,000 testing images
- Each image is 28×28 pixels, totaling 784 features per image
- The images are flattened into vectors of length 784 before being passed to the network

During this session, you’ll build and train several feed-forward models, starting with simple architectures and gradually increasing their complexity.

*!! First load and test Python and PyTorch. Your notebook is supposed to work with Python 3 (see the top right corner of the notebook).*
"""

# Commented out IPython magic to ensure Python compatibility.
import torch as th
import torch.nn as nn
import numpy as np
import pickle
import math, gzip
import matplotlib
import matplotlib.pyplot as plt
# %matplotlib inline
# %config InlineBackend.figure_formats=['svg']
# %config InlineBackend.figure_format = 'svg'
print(th.__version__) # should be greater or equal to 1.0

"""# Dataset

As already mentioned, we will use the Fashion-MNIST dataset for image classification. You can download it via torchvision, but, for simplicity, a preprocessed pickle file can be dowloaded using the link below.

## Download the dataset

**If you are using Colab --- prefered option**
"""

import gdown
url = 'https://drive.google.com/uc?id=1qx-a3KjzX2W66Aq84tnjGRUa10CTxOJN'
output = 'fashion-mnist.pk.gz'
gdown.download(url, output, quiet=False)

"""If you are using Jupyter"""

# To download the file with wget:
# ! wget -nc --no-check-certificate "https://drive.usercontent.google.com/download?id=1qx-a3KjzX2W66Aq84tnjGRUa10CTxOJN&confirm=t" -O "./fashion-mnist.pk.gz"

"""Check that the file has been downloaded (~43MB):"""

! ls -lh ./fashion-mnist.pk.gz

"""### Load the Dataset"""

fp = gzip.open('fashion-mnist.pk.gz','rb')
allXtrain, allYtrain, Xtest, Ytest, classlist  = pickle.load(fp)

"""**Important**: As mentioned before, the dataset is split in two parts, the training set and the test set. For thorough study and evaluation of machine learning models, **a good practice is to actually split the data into 3 sets:**

- **Training set**: to learn model parameters
- **Validation set**: to tune the hyperparameters and some design choices (the number and the size of the hidden layers, the dropout probability, ...)
- **Test set**: to evaluate the final model.

### Training / validation sets

To **speed up** training during this lab, we'll use only the **first 20 000 samples for training** and take out another **10 000 for validation**.
"""

Xtrain, Ytrain  = allXtrain[:20000]/255, allYtrain[:20000]
Xvalid, Yvalid  = allXtrain[20000:30000]/255, allYtrain[20000:30000]
print("Training   shape:" ,Xtrain.shape)
print("Validation shape:" ,Xvalid.shape)

"""To better understand the data you are dealing with it is crucial to explore it! In this case this is the training set stored in the variables **Xtrain and Ytrain**.

- Look at the dimension and type of the tensors stored in these variables.
- Print the classlist variable.
- Look at some examples to check consistency.

For that purpose you can **visualize** training examples like this:
"""

indices = np.arange(len(Xtrain))
nimages = 6
sel = np.random.choice(indices, nimages)
fig, axs = plt.subplots(1,nimages,figsize=(10,2))
for i,idx in enumerate(sel):
    axs[i].imshow(Xtrain[idx].numpy().reshape(28,28) , matplotlib.pyplot.cm.gray)

# print class list variable
print(classlist)

"""# Feedforward Neural Network

## PyTorch Sequential Module

In PyTorch, a feedforward neural network can be built using the **nn.Sequential container**. This allows you to stack layers in order, where:

- The first layer takes the input tensor.

- Each subsequent layer receives the output from the previous one.

This makes model definition concise and easy to read.


### IMPORTANT: Tensor Shapes in PyTorch -- Online Mode vs. Mini-Batch

PyTorch expects input data in the form of a 2D tensor with shape **(B, D)**, where:

- B is the batch size (number of examples),

- D is the input dimension (e.g., number of pixels in an image).

There are two common ways to feed data:

- **Online mode:** B = 1, for training or predicting one example at a time.

- **Mini-batch mode:** B > 1, for processing multiple examples simultaneously.


Note: if "B= Number of training example", you take all the training data at once. It is sometime called full-batch training.  


Even if you're passing a single example (B = 1), the input must still have two dimensions.
For example:

- A batch of 200 images: shape = (200, 784)
- A single image: shape = (1, 784) (not just (784,)!)
    
        

## Shallow Neural Network - no hidden layers

Let’s start with a very simple model:

- No hidden layers

- Just one input layer and one output layer, i.e., one linear transformation from 784 input pixels to 10 output classes

**Your task is to:**

- Propose an implementation of this linear model. Use **nn.Sequential** module as container to define your model.

- Train the model to classify images, i.e., maximize the log-likelihood of the correct class, or equivalently,   minimize the **Negative Log-Likelihood** (NLL) loss function (discussed in TD).

In PyTorch [documentation of the NNet package](https://pytorch.org/docs/stable/nn.html) you will find a section on the loss functions. Browse this section to find the appropriate one. It will also tell you how to design the output of the model.
"""

D_in = 784
D_out= 10

## -----------> TODO : replace "None" <----------------
model = nn.Sequential(nn.Linear(D_in,D_out),nn.LogSoftmax(dim=1))
loss_fn = nn.NLLLoss()

preds = model(Xtrain)
loss = loss_fn(preds, Ytrain) ## predictions your model will give
print("Shape:",preds.shape)
print("1st prediction:",th.exp(preds[0]))
print("Good answer:",Ytrain[0])
print(classlist)

"""#### Minibatch predictions

- Test the code on **a minibatch** of B examples

*NB. Don't confuse **minibatch** with **batchnorm** --- **Minibatch** is a training strategy where you split your full dataset into smaller minibatches (e.g., 32 or 64 samples per batch), and update model weights after computing gradients on each minibatch. And **BatchNorm** is a normalization layer added to neural networks to stabilize and speed up training by standardizing layer inputs.*



The code below corresponds to a prediction on a single image and then on 3 images.
*NB. Even when predicting a single image, the input should be 2D: use Xtrain[i:i+1] instead of Xtrain[i].*

- Look at the results, their shapes and values. Is it consistent with what you expect ?
- What do you think about the output ?
"""

B=1
i = 0
pred = model(Xtrain[i:i+B])
print(pred)


B=3
i = 0
pred = model(Xtrain[i:i+B])
print(pred)

"""- Do the same with the loss function."""

B=1
i=0
pred=model(Xtrain[i:i+B])
loss_fn = nn.NLLLoss()
loss = loss_fn(pred, Ytrain[i:i+B])
print(loss)

i=0
B=3
pred=model(Xtrain[i:i+B])
loss = loss_fn(pred, Ytrain[i:i+B])
print(loss)

"""Pourquoi est ce que la loss est différentes, on est pas surpris car c'est bien aléatoire et ça doit être en gros la même pour les différents batch

Les sortie sont des log probas donc tous entre -2 pk le model est pas bon dc tt les probas seront uniforme autour de 0.1 pour les classses prck on est pas bon

En gros notre model est trop simple et toutes les probas sont aléatoires, on a des probas uniforme et on peut pas conclure sur quel est le bon tenseur

### Training function

We now write **a generic training loop**. The code should generic so that it can handle different models and parameters.

**Your tasks:**

- Write a code to train a model with.
  - Optimizer: SGD -- stochastic gradient descent (you've seen it in TD)
  - Learning rate: 0.001
  - Epochs: 200

- Try different values of the learning rate.

Once you make it work, wrap your code in a function that you can reuse.

- Write a function that wraps everything you need to train the model and display results.
- Test is it with a different model.

Your function should:

- Track training and validation loss
- Report classification accuracy
- Show training curves


**NB on the structure of the output:** When you pass a batch of images through your model like this *output = model(X)*, you get a 2D tensor as output. In this tensor:

- each row corresponds to one image from your batch.
- each column corresponds to one of the possible labels (here 10, for the 10 Fashion-MNIST classes).

For example, if X contains a batch of 64 images, the output tensor will have shape: *torch.Size([64, 10])* Each value *output[i, j]* is the log-probability that the i-th image belongs to class j.
"""

## -----------> TODO generic training loop <----------------
Nepochs=200
lr=0.01
optimizer=th.optim.SGD(model.parameters(),lr=lr)
loss_fn=nn.NLLLoss()


for i in range(Nepochs):
  preds=model(Xtrain)
  loss=loss_fn(preds,Ytrain)
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()

## -----------> TODO: train function <----------------

def train_loop(model,loss_fn,optimizer,Xtrain,Ytrain,Xvalid,Yvalid,Nepoch):
  loss_history = []
  loss_valid=[]
  accuracy_training=[]
  accuracy_valid=[]

  for epoch in range(Nepoch):
    preds=model(Xtrain)
    loss=loss_fn(preds,Ytrain)
    loss_history.append(loss.item())
    accuracy_epoch2 = (preds.argmax(dim=1) == Ytrain).float().mean()
    accuracy_epoch2 = accuracy_epoch2.item()
    accuracy_training.append(accuracy_epoch2)
    if (epoch + 1) % 10 == 0:
            print(f"Epoch [{epoch+1}/{Nepoch}], Loss: {loss.item():.4f}")

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    preds=model(Xvalid)
    loss=loss_fn(preds,Yvalid)
    loss_valid.append(loss.item())
    accuracy_epoch = (preds.argmax(dim=1) == Yvalid).float().mean()
    accuracy_epoch = accuracy_epoch.item()
    accuracy_valid.append(accuracy_epoch)






  return loss,preds,loss_history,loss_valid,accuracy_valid,accuracy_training

model = nn.Sequential(nn.Linear(D_in,D_out),nn.LogSoftmax(dim=1))
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=0.1),Xtrain,Ytrain,Xvalid,Yvalid,400)

plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training')
plt.plot(loss_valid, label=' loss validation')

plt.title("Évolution des différentes loss")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy ")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

"""## Neural Network with one hidden layer

Now we have a function to train a neural model and evaluate the training process. This is your starting point for exploration of **different network architectures**.

Your next architecture will be a network with:

    One hidden layer of size 50

    Sigmoid activation

Write the model using the **nn.Sequential** module, and train it:

- for 30 epochs with learning rates 0.001 and 0.0001
- for 50 epochs and the same learning rates
- What do you observe ? How do learning rates and number of epochs affect your results ?


"""

Nepoch=30

lr=0.01

model=nn.Sequential(nn.Linear(D_in,50),nn.Sigmoid(),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)

plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training')
plt.plot(loss_valid, label=' loss validation')

plt.title("Évolution des différentes loss")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy ")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()






lr=0.1

model=nn.Sequential(nn.Linear(D_in,50),nn.Sigmoid(),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)

plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training')
plt.plot(loss_valid, label=' loss validation')

plt.title("Évolution des différentes loss")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy ")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

Nepoch=50

lr=0.01

model=nn.Sequential(nn.Linear(D_in,50),nn.Sigmoid(),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)

plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training')
plt.plot(loss_valid, label=' loss validation')

plt.title("Évolution des différentes loss")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy ")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()






lr=0.1

model=nn.Sequential(nn.Linear(D_in,50),nn.Sigmoid(),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)

plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training')
plt.plot(loss_valid, label=' loss validation')

plt.title("Évolution des différentes loss")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy ")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

"""## SGD with momentum

Up to now, you have trained your NNets using the SGD optimizer. This works fine but in general SGD can be slow to converge, especially when the loss surface has gorges with steep sides, i.e., regions where the gradient changes steeply in some directions and slowly in others. This can cause the optimization to zigzag and take longer to reach a minimum.

A way to overcome this problem is to use **momentum** -- a parameter in SGD optimizer that helps accelerate training, especially in tricky regions. Basically, instead of updating parameters purely based on the current gradient, we also consider the previous updates. This creates a sort of "velocity" that helps smooth out the path and push through small oscillations.

**Your task:**

- Add the moment term to the optimizer (try 0.9)
- See the impact on the training, with different values.
"""

lr=0.1
Nepoch=150
model=nn.Sequential(nn.Linear(D_in,50),nn.Sigmoid(),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
for i in range(10):
  max=[]
  L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.1*i),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)

  plt.figure(figsize=(10, 5))
  plt.plot(loss_training, label='loss training')
  plt.plot(loss_valid, label=' loss validation')

  plt.title("Évolution des différentes loss")
  plt.xlabel("Nombre d'itération")
  plt.ylabel("Perte")
  plt.legend()
  plt.grid(True)


  plt.figure(figsize=(10, 5))
  plt.plot(acc_train, label='Training accuracy'f{i})
  plt.plot(acc_valid, label='Validation accuracy'f{i})
  max.append(max(acc_train),max(acc_valid))
  plt.title("Évolution des différentes accuracy ")
  plt.xlabel("Nombre d'itération")
  plt.ylabel("Accuracy")
  plt.legend()
  plt.grid(True)
  plt.show()


print(max)

"""L'accuracy qui redescent ou ne fait pas que monter est un bug ou un artefax parce que normalement elle doit faire que monter et c'est bien le cas quand on modifie les accuracy"""



"""## From Sigmoid to ReLU activation

**Your task:**

- Consider lr=0.0001 and train your model with a ReLU activation.
- Compare the results to the Sigmoid.
"""

lr=0.01
Nepoch=150
model=nn.Sequential(nn.Linear(D_in,50),nn.ReLU(),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)

plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

lr=0.01
Nepoch=150
model=nn.Sequential(nn.Linear(D_in,50),nn.Sigmoid(),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training')
plt.plot(loss_valid, label=' loss validation')

plt.title("Évolution des différentes loss Sigmoid")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy Sigmoid")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

"""Problèmes sur la fonction accuracy on voit qu'elle a des difficultés à faire que monter et quelle va chercher un plateau après certaines itérations alors que avec RELU on a pas de retour c'est des artefacts

## Impact of the hidden layer size

Run experiments with different hidden layer sizes.

    Try: 50,100,150,200 and 250.

- What do you observe ?
"""

lr=0.1
Nepoch=50
model=nn.Sequential(nn.Linear(D_in,250),nn.ReLU(),nn.Linear(250,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()



Nepoch=50
model=nn.Sequential(nn.Linear(D_in,200),nn.ReLU(),nn.Linear(200,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()


Nepoch=50
model=nn.Sequential(nn.Linear(D_in,150),nn.ReLU(),nn.Linear(150,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()


Nepoch=50
model=nn.Sequential(nn.Linear(D_in,100),nn.ReLU(),nn.Linear(100,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

Nepoch=50
model=nn.Sequential(nn.Linear(D_in,50),nn.ReLU(),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

"""## Deeper network -- two hidden layers

Now we add one more hidden layer to our architecture.

To start with, consider:

    Two hidden layers of size 50

    Activation: ReLU
    
    Learning rate: 0.0001

    Train for 100 epochs
    
"""

lr=0.1
Nepoch=100
model=nn.Sequential(nn.Linear(D_in,50),nn.ReLU(),nn.Linear(50,50),nn.ReLU(),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

"""On voit vrm une différence, le dropout values a permit de supprimer les instabilités et ainsi d'avoir une courbe plus lisse et plus exploitable on voit vraiment une différence très importante

Try different dropout values (e.g., 0.3, 0.5)
    
NB: When you apply dropout with a certain probability **p**, each neuron in a given layer has a chance **p** of being dropped during training. This forces the network to not rely too heavily on any single neuron, which improves generalization. The value 0.3 is used for mild regularization, i.e., when you have a small or simple network; 0.5 corresponds to stronger regularization and is a typically used for deeper or overfitting networks.
"""

lr=0.1
Nepoch=100
model=nn.Sequential(nn.Linear(D_in,50),nn.ReLU(),nn.Dropout(0.1),nn.Linear(50,50),nn.ReLU(),nn.Dropout(0.1),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()



lr=0.1
Nepoch=100
model=nn.Sequential(nn.Linear(D_in,50),nn.ReLU(),nn.Dropout(0.5),nn.Linear(50,50),nn.ReLU(),nn.Dropout(0.5),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

"""On voit vrm une différence, le dropout values a permit de supprimer les instabilités et ainsi d'avoir une courbe plus lisse et plus exploitable on voit vraiment une différence très importante et c'est une vraie avancée pour améliorer de comment le modèle peut apprendre les performances sont optimales et efficient

Play with different hyperparameters:

    Larger hidden layers (double it for example)

    Adding a third hidden layer
"""

lr=0.1
Nepoch=100
model=nn.Sequential(nn.Linear(D_in,100),nn.ReLU(),nn.Dropout(0.5),nn.Linear(100,100),nn.ReLU(),nn.Dropout(0.5),nn.Linear(100,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()




lr=0.1
Nepoch=100
model=nn.Sequential(nn.Linear(D_in,250),nn.ReLU(),nn.Dropout(0.5),nn.Linear(250,250),nn.ReLU(),nn.Dropout(0.5),nn.Linear(250,50),nn.ReLU(),nn.Dropout(0.5),nn.Linear(50,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

"""## Add Batch Normalization

BatchNorm helps deeper networks train faster and more reliably.

**Your task:**

- Build a neural network with 2 hidden layers.
- Insert Batch Normalization block where it is useful.
- Train the model and compare the optimization speed.


"""

lr=0.01
Nepoch=100
model=nn.Sequential(nn.Linear(D_in,250),nn.ReLU(),nn.Dropout(0.3),nn.BatchNorm1d(250),nn.Linear(250,100),nn.ReLU(),nn.Dropout(0.3),nn.BatchNorm1d(100),nn.Linear(100,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),Xtrain,Ytrain,Xvalid,Yvalid,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Évolution des différentes loss RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Évolution des différentes accuracy RELU")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

"""## Online learning vs. mini-batch vs. full-batch training

In practice, it’s not always possible to train a model on the entire dataset at once — either due to memory limitations or the nature of the application (e.g., streaming data). This is where different training strategies come into play:


- Online Training (Stochastic Gradient Descent)

        - The model is updated one example at a time.

        - At each step, a single image is selected (often randomly), and the gradient is computed and used to update the model.

        - This introduces a lot of noise but can be useful when data arrives sequentially or memory is tight.

        - In theory converges faster, very fast per-step, but in practice not efficient in terms of computation time.
        


- Mini-Batch Training

        A middle ground: the training data is split into small batches of size B; the split changes at each epoch.

        The model is updated after computing the gradient on each batch.

        Offers a good trade-off between computational efficiency and gradient stability.

        Usually used in deep learning frameworks: it allows us a tradeoff in terms of memory requirement.
        
     

- Full-Batch Training

        The gradient is computed over the entire training set before each update.

        This produces the most accurate gradient estimate, but:

            Requires loading all the data at once.

            Can be very slow per update, especially for large datasets.


To fully explore different training strategies, compare them directly on your datatset.

**Your task:**

- Make a comparison in terms of computational efficiency to do one training epoch with: online, mini-batch (B=200) and full training.

- Then make a convergence speed comparison between these 3 training methods: how many epochs are needed to reach good performance ?

*NB: it is important to always adapt the learning rate to have nice performance!*


"""

def train_loop_online(model, loss_fn, optimizer, Xtrain, Ytrain, Xvalid, Yvalid, Nepoch):
    loss_history = []
    loss_valid = []
    accuracy_training = []
    accuracy_valid = []

    N_samples = len(Xtrain) # Nombre total d'exemples

    for epoch in range(Nepoch):

        # --- DÉBUT DU ONLINE TRAINING ---
        # On mélange les index pour que l'ordre change à chaque époque (recommandé pour SGD)
        indices = th.randperm(N_samples)

        for i in indices:
            # 1. On extrait UN SEUL exemple (et sa réponse)

            X_sample = Xtrain[i:i+1]
            Y_sample = Ytrain[i:i+1]
            if len(X_sample.shape) == 1:
              X_sample = X_sample.unsqueeze(0) # Transforme [250] en [1, 250]
            if len(Y_sample.shape) == 0:
              Y_sample = Y_sample.unsqueeze(0)

            # 2. Prédiction sur cet unique exemple
            preds = model(X_sample)
            loss = loss_fn(preds, Y_sample)


            # 3. Mise à jour immédiate des poids (C'est ça le Online Training)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()


            with th.no_grad():
            # Sur le Train (pour voir l'évolution globale)
              full_preds_train = model(Xtrain)
              epoch_loss = loss_fn(full_preds_train, Ytrain).item()
              loss_history.append(epoch_loss)

              acc_train = (full_preds_train.argmax(dim=1) == Ytrain).float().mean().item()
              accuracy_training.append(acc_train)

              # Sur la Validation
              preds_val = model(Xvalid)
              loss_v = loss_fn(preds_val, Yvalid).item()
              loss_valid.append(loss_v)

              acc_val = (preds_val.argmax(dim=1) == Yvalid).float().mean().item()
              accuracy_valid.append(acc_val)

            if (epoch + 1) % 10 == 0:
              print(f"Epoch [{epoch+1}/{Nepoch}], Loss: {epoch_loss:.4f}")


    return loss, preds, loss_history, loss_valid, accuracy_valid, accuracy_training

#Online training
lr=0.00001
Nepoch=100
model=nn.Sequential(nn.Linear(D_in,250),nn.Sigmoid(),nn.Dropout(0.3),nn.Linear(250,100),nn.Sigmoid(),nn.Dropout(0.3),nn.Linear(100,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop_online(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),allXtrain[15511:15700],allYtrain[15511:15700],allXtrain[1220:1449],allYtrain[1220:1449],Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("Online Batch")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Online batch ")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

#mini-batch
lr=0.01
Nepoch=100
model=nn.Sequential(nn.Linear(D_in,250),nn.ReLU(),nn.Dropout(0.3),nn.BatchNorm1d(250),nn.Linear(250,100),nn.ReLU(),nn.Dropout(0.3),nn.BatchNorm1d(100),nn.Linear(100,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),allXtrain[15000:15200],allYtrain[15000:15200],allXtrain[13400:13600],allYtrain[13400:13600],Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("mini Batch")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("Mini batch ")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

#mini-batch
lr=0.01
Nepoch=10
model=nn.Sequential(nn.Linear(D_in,250),nn.ReLU(),nn.Dropout(0.3),nn.BatchNorm1d(250),nn.Linear(250,100),nn.ReLU(),nn.Dropout(0.3),nn.BatchNorm1d(100),nn.Linear(100,D_out),nn.LogSoftmax(dim=1))
loss_fn=nn.NLLLoss()
L,Y,loss_training,loss_valid,acc_valid,acc_train=train_loop(model,loss_fn,th.optim.SGD(model.parameters(),lr=lr,momentum=0.9),allXtrain,allYtrain,allXtrain,allYtrain,Nepoch)
plt.figure(figsize=(10, 5))
plt.plot(loss_training, label='loss training ')
plt.plot(loss_valid, label=' loss validation ')

plt.title("allset")
plt.xlabel("Nombre d'itération")
plt.ylabel("Perte")
plt.legend()
plt.grid(True)


plt.figure(figsize=(10, 5))
plt.plot(acc_train, label='Training accuracy')
plt.plot(acc_valid, label='Validation accuracy')
plt.title("All set ")
plt.xlabel("Nombre d'itération")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

"""
## Dropout layer to prevent overfitting -- in more details

Even though Fashion-MNIST is a relatively simple dataset, it is still very easy to overfit, especially with small models and limited regularization.

To remind you (you discussed this in TD) overfitting means:

    Your model performs well on the training set (from TD - the fitted curve went through all the datapoints),

    But performs poorly on unseen data (from TD - the curve would change if you added new data, i.e., the fit (model) cannot be generalized).

Dropout is a regularization technique that randomly **drops** a fraction of neurons during training (e.g., 20% with p=0.2). This forces the model to not rely too much on any one feature or path!

- During training dropout randomly sets activations to zero with probability p.

- During evaluation dropout turns off, and the full network is used.

In the section on Deeper networks above, you already played with the dropout option. When applied after a single hidden layer, it helps prevent overfitting in a shallow model. If, however, it is applied after each hidden layer in a deeper network, it is addressing overfitting across more complex representations, where the risk of memorization is higher.

**Your task:**

- Code this modification (with p=0.2), rerun the training process and compare the training curves.

As stated, when you use a Dropout layer, the layer acts differently in the train mode and evaluation mode. You should take this into account when you train the model and when you compute the performance on the validation set.
"""

model_dropout=nn.Sequential(nn.Linear(D_in,250),nn.ReLU(),nn.Dropout(0.2),nn.BatchNorm1d(250),nn.Linear(250,100),nn.ReLU(),nn.Dropout(0.2),nn.BatchNorm1d(100),nn.Linear(100,D_out),nn.LogSoftmax(dim=1))

def train_loop_dropout(model, loss_fn, optimizer, Xtrain, Ytrain, Xvalid, Yvalid, Nepoch):
    loss_history = []
    loss_valid_history = []
    acc_train_history = []
    acc_valid_history = []

    for epoch in range(Nepoch):

        model.train()

        preds = model(Xtrain)
        loss = loss_fn(preds, Ytrain)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()


        loss_history.append(loss.item())
        acc = (preds.argmax(dim=1) == Ytrain).float().mean().item()
        acc_train_history.append(acc)


        model.eval()

        with th.no_grad(): # On ne calcule pas les gradients pour la validation
            preds_val = model(Xvalid)
            loss_v = loss_fn(preds_val, Yvalid)

            # Enregistrement Loss Validation
            loss_valid_history.append(loss_v.item())
            acc_v = (preds_val.argmax(dim=1) == Yvalid).float().mean().item()
            acc_valid_history.append(acc_v)

        if (epoch + 1) % 10 == 0:
            print(f"Epoch [{epoch+1}/{Nepoch}] | Train Loss: {loss.item():.4f} | Val Loss: {loss_v.item():.4f}")

    return loss_history, loss_valid_history, acc_train_history, acc_valid_history

lr = 0.01
Nepoch = 200

loss_fn = nn.NLLLoss()
optimizer = th.optim.SGD(model_dropout.parameters(), lr=lr, momentum=0.9)


loss_train, loss_val, acc_train, acc_val = train_loop_dropout(
    model_dropout, loss_fn, optimizer,
    Xtrain, Ytrain, Xvalid, Yvalid, Nepoch
)

# --- Visualisation ---
plt.figure(figsize=(12, 5))

# Graphique de la Loss
plt.subplot(1, 2, 1)
plt.plot(loss_train, label='Training Loss (avec Dropout)')
plt.plot(loss_val, label='Validation Loss (sans Dropout)')
plt.title("Évolution de la Loss avec Dropout")
plt.xlabel("Époques")
plt.ylabel("Loss")
plt.legend()
plt.grid(True)

# Graphique de l'Accuracy
plt.subplot(1, 2, 2)
plt.plot(acc_train, label='Training Accuracy')
plt.plot(acc_val, label='Validation Accuracy')
plt.title("Évolution de l'Accuracy")
plt.xlabel("Époques")
plt.ylabel("Précision")
plt.legend()
plt.grid(True)

plt.show()